{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import hyperopt\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not list(actual):\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 1110.8 Mb\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('/opt/devs/pershin/kf/train.csv')\n",
    "data_train.drop('row_id', axis=1, inplace=True)\n",
    "\n",
    "print('Train data size: {:0.01f} Mb'.format(data_train.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 262.7 Mb\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv('/opt/devs/pershin/kf/test.csv')\n",
    "data_test.drop('row_id', axis=1, inplace=True)\n",
    "\n",
    "print('Test data size: {:0.01f} Mb'.format(data_test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rare_places(data: pd.DataFrame, min_n=10):\n",
    "    place_counts = data.place_id.value_counts()\n",
    "    mask = place_counts[data.place_id.values] >= min_n\n",
    "    return data.loc[mask.values]\n",
    "\n",
    "def filter_rare_classes(X, y, min_n=10, return_indices=False):\n",
    "    _class, _class_count = np.unique(y, return_counts=True)\n",
    "    _rare_place_ids_indices = np.zeros_like(y).astype(bool)\n",
    "    for rare_place_id in _class[_class_count < min_n]:\n",
    "        _rare_place_ids_indices[y == rare_place_id] = True\n",
    "    if return_indices:\n",
    "        return X[~_rare_place_ids_indices,:], y[~_rare_place_ids_indices], (~_rare_place_ids_indices)\n",
    "    else:\n",
    "        return X[~_rare_place_ids_indices,:], y[~_rare_place_ids_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_n_indices(array: np.array, n: int):\n",
    "    return array.argsort()[::-1][:n]\n",
    "\n",
    "def get_n_most_frequent(array: np.array, n: int):\n",
    "    vals, counts = np.unique(array, return_counts=True)\n",
    "    return vals[counts.argsort()[::-1][:n]]\n",
    "\n",
    "def replicate(array: np.array):\n",
    "    return np.concatenate([[val]*(len(array) - i) for i,val in enumerate(array)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_time(data, train_size=78):\n",
    "    time_validate_threshold = np.percentile(data.time.values, train_size)  # as train data ~22% of train+test data\n",
    "\n",
    "    train_indices = data.time.values < time_validate_threshold\n",
    "    train_place_ids = np.unique(data.place_id.iloc[train_indices].values)\n",
    "    \n",
    "    test_indices = (data.time.values >= time_validate_threshold) & np.in1d(data.place_id.values, train_place_ids)\n",
    "    test_place_ids = np.unique(data.place_id.iloc[test_indices].values)\n",
    "    \n",
    "    return data.iloc[train_indices, :], data.iloc[test_indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data: pd.DataFrame):\n",
    "    data['hour'] = (data.time.values / 60) % 24  # keep the minutes info\n",
    "    data['weekday'] = ((data.time.values // 60) / 24) % 7\n",
    "    data['day'] = ((data.time.values // 60) / 24) % 30\n",
    "    data['month'] = ((data.time.values // (60 * 24)) / 30) % 12\n",
    "    data['year'] = data.time.values // (60 * 24 * 365)\n",
    "    data['x_d_y'] = data.x.values / (data.y.values + 1e-5)\n",
    "    data['x_t_y'] = data.x.values * data.y.values\n",
    "    \n",
    "    accuracy_through_time = data.sort_values(by='time')[['time', 'accuracy']].groupby('time').agg(np.median)\n",
    "    median_accuracy_through_days = pd.rolling_median(accuracy_through_time, window=60*24)\n",
    "    data['accuracy_diff'] = data.accuracy.values - median_accuracy_through_days.loc[data.time].accuracy.values\n",
    "    data['accuracy_diff'][np.isnan(data['accuracy_diff'])] = 0\n",
    "    \n",
    "    data['log10_accuracy'] = np.log10(data.accuracy.values)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = add_features(data_train)\n",
    "data_test = add_features(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cv = data_train.query('0.25 < x < 0.5 and 0.25 < y < 0.5')\n",
    "data_cv = data_train.query('0 < x < 1 and 0 < y < 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = add_features(data_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [\n",
    "    'x', 'y', 'x_d_y', 'x_t_y',\n",
    "    'hour', 'weekday', 'month', 'year',\n",
    "    'accuracy', 'accuracy_diff'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_features_to_use = ['x', 'y', 'log10_accuracy', 'hour', 'weekday', 'time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEstimator:\n",
    "    def __init__(self, estimator, bandwidths_for_kde_features, features_probas_weights):\n",
    "        self.estimator = estimator\n",
    "        self.bandwidths_for_kde_features = bandwidths_for_kde_features\n",
    "        self.features_probas_weights = features_probas_weights\n",
    "        \n",
    "    def query(self, train_data: pd.DataFrame, test_data: pd.DataFrame,\n",
    "              feature_names, kde_features_names, grid_size, epsilan, min_place_id_occurences=0):\n",
    "        x_cells = grid_size[0]\n",
    "        y_cells = grid_size[1]\n",
    "        x_range = np.linspace(train_data.x.min(), train_data.x.max(), num=x_cells+1)\n",
    "        y_range = np.linspace(train_data.y.min(), train_data.y.max(), num=y_cells+1)\n",
    "        x_range[-1] = np.inf\n",
    "        y_range[-1] = np.inf\n",
    "\n",
    "        margin_x = ((train_data.x.max() - train_data.x.min()) / x_cells) * epsilan[0]\n",
    "        margin_y = ((train_data.y.max() - train_data.y.min()) / y_cells) * epsilan[1]\n",
    "        \n",
    "        places_features_kdes = {}\n",
    "        for _feature in self.bandwidths_for_kde_features:\n",
    "            places_features_kdes[_feature] = filter_rare_places(train_data).groupby('place_id').apply(\n",
    "                lambda x: KernelDensity(\n",
    "                    kernel='gaussian',\n",
    "                    metric='manhattan',\n",
    "                    bandwidth=self.bandwidths_for_kde_features[_feature]\n",
    "                ).fit(\n",
    "                    np.vstack([\n",
    "                        x[_feature].values[:, np.newaxis] - features_periods[_feature],\n",
    "                        x[_feature].values[:, np.newaxis],\n",
    "                        x[_feature].values[:, np.newaxis] + features_periods[_feature]\n",
    "                    ]) if features_periods[_feature] else x[_feature].values[:, np.newaxis]\n",
    "                )\n",
    "            )   \n",
    "  \n",
    "        \n",
    "        predictions = np.zeros((len(test_data), 3))\n",
    "\n",
    "        for x_min, x_max in zip(x_range[:-1], x_range[1:]):\n",
    "            for y_min, y_max in zip(y_range[:-1], y_range[1:]):\n",
    "\n",
    "                _train_idx = \\\n",
    "                    ((x_min - margin_x) <= train_data.x.values) & \\\n",
    "                    (train_data.x.values < (x_max + margin_x)) & \\\n",
    "                    ((y_min - margin_y) <= train_data.y.values) & \\\n",
    "                    (train_data.y.values < (y_max + margin_y))\n",
    "                \n",
    "                _test_idx = \\\n",
    "                    ((x_min) <= test_data.x.values) & \\\n",
    "                    (test_data.x.values < (x_max)) & \\\n",
    "                    ((y_min) <= test_data.y.values) & \\\n",
    "                    (test_data.y.values < (y_max))\n",
    "\n",
    "\n",
    "                _train_data = filter_rare_places(train_data[_train_idx], min_n=min_place_id_occurences)\n",
    "                _test_data  = test_data[_test_idx]\n",
    "    \n",
    "                _X_train = _train_data[feature_names].values            \n",
    "                _X_test = _test_data[feature_names].values\n",
    "            \n",
    "                le = LabelEncoder()\n",
    "                _y_train = le.fit_transform(_train_data.place_id.values)\n",
    "\n",
    "                places_kde_probas  = []\n",
    "                for _feature in kde_features:\n",
    "\n",
    "                    _places_kde_probas  = np.empty((len(_X_test),  len(le.classes_)))\n",
    "\n",
    "                    for _j, _place_id in enumerate(le.classes_):\n",
    "                        _places_kde_probas[:,_j] = np.exp(\n",
    "                            places_features_kdes[_feature][_place_id].score_samples(\n",
    "                                _test_data[_feature].values[:, np.newaxis]\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    if self.features_probas_weights:                            \n",
    "                        _places_kde_probas = _places_kde_probas.mean() + \\\n",
    "                            (_places_kde_probas - _places_kde_probas.mean()) * \\\n",
    "                            self.features_probas_weights[_feature]\n",
    "                    \n",
    "                    places_kde_probas.append(_places_kde_probas)\n",
    "\n",
    "                places_kde_probas = np.prod(places_kde_probas, axis=0)\n",
    "\n",
    "\n",
    "                self.estimator.fit(_X_train, _y_train)\n",
    "                \n",
    "                _pred_probas = self.estimator.predict_proba(_X_test)\n",
    "                _pred_probas = _pred_probas * places_kde_probas\n",
    "\n",
    "                _y_pred = _pred_probas.argsort(axis=1)[:,::-1][:,:3]\n",
    "                predictions[_test_idx, :] = le.inverse_transform(_y_pred)\n",
    "        \n",
    "        return predictions.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These are some hyperparameters that have been estimated with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidths_for_kde_features = {\n",
    "    'x': 1e-2,\n",
    "    'y': 5e-3,\n",
    "    'log10_accuracy': 2e-1,\n",
    "    'time': 1e5,\n",
    "    'hour': 2e0,\n",
    "    'weekday':6e-1,\n",
    "    'day': 4e-1,\n",
    "    'month': 1e0\n",
    "}\n",
    "\n",
    "features_periods = {\n",
    "    'x': 0,\n",
    "    'y': 0,\n",
    "    'log10_accuracy': 0,\n",
    "    'time': 0,\n",
    "    'hour': 24,\n",
    "    'weekday': 7,\n",
    "    'day': 30,\n",
    "    'month': 12\n",
    "}\n",
    "\n",
    "features_probas_weights = {\n",
    "    'hour': 0.957,\n",
    "    'log10_accuracy': 0.909,\n",
    "    'time': 0.721,\n",
    "    'weekday': 0.225,\n",
    "    'x': 0.525,\n",
    "    'y': 0.985\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6009\n",
      "time spend: 834.1s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = GridEstimator(\n",
    "    xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.15,\n",
    "        objective='multi:softprob',\n",
    "        nthread=4,\n",
    "        subsample=0.525,\n",
    "        colsample_bytree=0.9,\n",
    "        seed=0\n",
    "    ),\n",
    "    bandwidths_for_kde_features=bandwidths_for_kde_features,\n",
    "    features_probas_weights=features_probas_weights\n",
    ")\n",
    "\n",
    "cv_train_data, cv_validate_data = train_test_split_by_time(data_cv)\n",
    "\n",
    "cv_y_valid = cv_validate_data.place_id.values.reshape(-1,1)\n",
    "cv_y_pred = model.query(\n",
    "    cv_train_data,\n",
    "    cv_validate_data,\n",
    "    features_to_use,\n",
    "    kde_features_to_use,\n",
    "    grid_size=(8, 12),\n",
    "    epsilan=(0.7, 0.1),\n",
    "    min_place_id_occurences=10\n",
    ")\n",
    "\n",
    "cv_score = mapk(cv_y_valid, cv_y_pred, k=3)\n",
    "\n",
    "end_time = time.time()\n",
    "print('{:0.04f}'.format(cv_score))\n",
    "print('time spend: {:0.01f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridEstimator(\n",
    "    xgb.XGBClassifier(\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.15,\n",
    "        objective='multi:softprob',\n",
    "        nthread=4,\n",
    "        subsample=0.525,\n",
    "        colsample_bytree=0.9,\n",
    "        seed=0\n",
    "    ),\n",
    "    bandwidths_for_kde_features=bandwidths_for_kde_features,\n",
    "    features_probas_weights=features_probas_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "y_pred = model.query(\n",
    "    data_train,\n",
    "    data_test,\n",
    "    features_to_use,\n",
    "    kde_features_to_use,\n",
    "    grid_size=(80, 120),\n",
    "    epsilan=(0.7, 0.1),\n",
    "    min_place_id_occurences=10\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print('Completed! Time spend: {:0.01f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/y_pred.csv', 'w') as f:\n",
    "    print('row_id,place_id', file=f)\n",
    "    for row, prediction in enumerate(y_pred):\n",
    "        print('{},{}'.format(row, ' '.join(prediction.astype(int).astype(str))), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}